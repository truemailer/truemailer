"""
main.py  — Truemailer core API

How to run:
    uvicorn main:app --host 0.0.0.0 --port 8000 --reload

Files used by this app (expected paths; update if you keep different):
    - blocklist/blocklist.txt        (one domain per line)  <- generated by updater.py
    - blocklist.json                 (optional JSON list)
    - allowlist/allowlist.json       (array of trusted domains) OR allowlist.json
    - keys.json                      (map of client keys or generated by keygen.py)
    - client.json                    (per-client usage tracking)
    - mx_cache.json                  (optional; persistent cache for MX checks)
Notes:
    - This file is intentionally self-contained. It will not modify updater.py, worker, or other files.
    - The verify logic checks allowlist first, then blocklist, then heuristics, then MX.
"""

import os
import re
import json
import time
import math
import threading
from pathlib import Path
from typing import Optional
from datetime import datetime, timedelta

import dns.resolver
from fastapi import FastAPI, HTTPException, Request, Body
from pydantic import BaseModel, EmailStr

# -----------------------
# CONFIG
# -----------------------
APP_NAME = "Truemailer"
MASTER_KEY = os.environ.get("TRUEMAILER_MASTER_KEY", "master_demo_key")  # protect create-key endpoint
MX_CACHE_FILE = "mx_cache.json"
BLOCKLIST_TXT = "blocklist/blocklist.txt"
BLOCKLIST_JSON = "blocklist.json"
ALLOWLIST_JSON1 = "allowlist/allowlist.json"
ALLOWLIST_JSON2 = "allowlist.json"
KEYS_FILE = "keys.json"
CLIENT_FILE = "client.json"

# Rate limit defaults
DEFAULT_DAILY_LIMIT = 1000  # default if key doesn't specify
# -----------------------

app = FastAPI(title=f"{APP_NAME} Email Verification API")

# -----------------------
# Utilities: safe file IO
# -----------------------
def read_json(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

def write_json(path, data):
    os.makedirs(os.path.dirname(path), exist_ok=True) if "/" in path else None
    tmp = f"{path}.tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)
    os.replace(tmp, path)

def read_lines(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return [ln.strip() for ln in f if ln.strip()]
    except Exception:
        return []

# -----------------------
# Load / watch lists
# -----------------------
# We'll keep lists in memory for speed and provide an endpoint to refresh them manually.
LIST_LOCK = threading.Lock()
BLOCKSET = set()
ALLOWSET = set()

def load_blocklist():
    global BLOCKSET
    s = set()
    # try blocklist/blocklist.txt first
    for p in (BLOCKLIST_TXT, BLOCKLIST_JSON):
        if os.path.exists(p):
            if p.endswith(".txt"):
                for ln in read_lines(p):
                    ln = ln.strip().lower()
                    if ln:
                        s.add(ln)
            else:
                v = read_json(p)
                if isinstance(v, list):
                    for ln in v:
                        if isinstance(ln, str):
                            s.add(ln.strip().lower())
    BLOCKSET = s
    return len(BLOCKSET)

def load_allowlist():
    global ALLOWSET
    s = set()
    for p in (ALLOWLIST_JSON1, ALLOWLIST_JSON2):
        if os.path.exists(p):
            v = read_json(p)
            if isinstance(v, dict):
                # handle {"trusted": [ ... ]}
                arr = v.get("trusted") or v.get("allow") or v.get("domains") or v.get("trusted_domains")
                if isinstance(arr, list):
                    for d in arr:
                        if isinstance(d, str):
                            s.add(d.strip().lower())
            elif isinstance(v, list):
                for d in v:
                    if isinstance(d, str):
                        s.add(d.strip().lower())
    # Some basic defaults if allowlist empty (helpful)
    if not s:
        s.update(["gmail.com","yahoo.com","outlook.com","hotmail.com","icloud.com","zoho.com","protonmail.com"])
    ALLOWSET = s
    return len(ALLOWSET)

def reload_lists():
    with LIST_LOCK:
        bcount = load_blocklist()
        acount = load_allowlist()
    return {"block_count": bcount, "allow_count": acount}

# load at startup
reload_lists()

# -----------------------
# Load key / client storage
# -----------------------
def load_keys():
    k = read_json(KEYS_FILE)
    if not isinstance(k, dict):
        k = {}
    # keys may be stored as client_name -> {key:..., expiry:...} or key->info
    # normalize to key -> info map when needed by helper functions
    return k

def load_clients():
    c = read_json(CLIENT_FILE)
    if not isinstance(c, dict):
        c = {}
    return c

# -----------------------
# MX cache (simple persistent)
# -----------------------
MX_CACHE = {}
MX_LOCK = threading.Lock()
def load_mx_cache():
    global MX_CACHE
    d = read_json(MX_CACHE_FILE)
    if isinstance(d, dict):
        MX_CACHE = d
    else:
        MX_CACHE = {}

def save_mx_cache():
    with MX_LOCK:
        write_json(MX_CACHE_FILE, MX_CACHE)

load_mx_cache()

# TTL for MX cache: 7 days
MX_TTL = 7 * 24 * 3600

def check_mx(domain, timeout=3.0):
    domain = domain.lower()
    now = int(time.time())
    with MX_LOCK:
        if domain in MX_CACHE:
            rec = MX_CACHE[domain]
            if now - rec.get("ts", 0) < MX_TTL:
                return rec.get("mx", False)
    # do DNS MX check
    try:
        answers = dns.resolver.resolve(domain, "MX", lifetime=timeout)
        ok = len(answers) > 0
    except Exception:
        ok = False
    with MX_LOCK:
        MX_CACHE[domain] = {"mx": bool(ok), "ts": now}
    # auto-save in background occasionally
    if int(time.time()) % 10 == 0:
        try:
            save_mx_cache()
        except Exception:
            pass
    return ok

# -----------------------
# Email format regex + heuristics
# -----------------------
EMAIL_RE = re.compile(r"^[A-Za-z0-9._%+\-]+@[A-Za-z0-9.\-]+\.[A-Za-z]{2,}$")

def normalize_domain(domain: str) -> str:
    return domain.strip().lower()

def is_valid_format(email: str) -> bool:
    return EMAIL_RE.match(email) is not None

def heuristic_suspicious(email: str):
    """Return dict with suspicious boolean and reasons list."""
    reasons = []
    local, _, domain = email.partition("@")
    if len(local) <= 1:
        reasons.append("short-local")
    if ".." in email:
        reasons.append("dots")
    # many numbers in user
    digits = sum(ch.isdigit() for ch in local)
    if digits / max(1, len(local)) > 0.6:
        reasons.append("many-digits")
    return {"suspicious": len(reasons) > 0, "reasons": reasons}

# -----------------------
# Key validation & rate limiting
# -----------------------
def find_client_by_key(api_key: str):
    # try keys.json first (clientName -> info) where info may contain key field
    keys_map = load_keys()
    # Keys storage may be either: {client_name: {"key":k, ...}} or {key: info}
    # handle both
    # 1) direct map where key is value
    for cname, info in keys_map.items():
        if isinstance(info, dict) and info.get("key") == api_key:
            return cname, info
    # 2) map where top-level keys are keys
    if api_key in keys_map:
        return keys_map[api_key].get("client", api_key), keys_map[api_key]
    return None, None

def is_key_valid(api_key: str):
    cname, info = find_client_by_key(api_key)
    if not info:
        return False, "invalid-key", None
    # check expiry if present
    expiry = info.get("expiry")
    if expiry and int(time.time()) > int(expiry):
        return False, "expired", cname
    return True, "ok", cname

def increment_usage(client_name: str):
    clients = load_clients()
    client = clients.get(client_name, {})
    now = int(time.time())
    # daily reset at midnight UTC simple approach
    today = datetime.utcnow().strftime("%Y-%m-%d")
    meta = client.get("_meta", {})
    if meta.get("day") != today:
        meta["day"] = today
        meta["count"] = 0
    meta["count"] = meta.get("count", 0) + 1
    client["_meta"] = meta
    client["last_used"] = now
    clients[client_name] = client
    write_json(CLIENT_FILE, clients)
    return meta["count"]

def get_daily_usage(client_name: str):
    clients = load_clients()
    client = clients.get(client_name, {})
    meta = client.get("_meta", {})
    return meta.get("count", 0)

# -----------------------
# Core verify logic (no change to main.py required for other files)
# -----------------------
def verify_email_address(email: str):
    """Return a dict result: {valid:bool, disposable:bool, reason:str, mx:bool, suspicious:bool, suspicious_reasons:[] }"""
    email = email.strip()
    if not is_valid_format(email):
        return {"valid": False, "disposable": False, "reason": "invalid_format", "mx": False, "suspicious": False, "suspicious_reasons": []}

    local, _, domain = email.rpartition("@")
    domain = normalize_domain(domain)

    # 1) allowlist quick check
    if domain in ALLOWSET or any(domain.endswith("." + a) for a in ALLOWSET):
        mx_ok = check_mx(domain)
        return {"valid": True, "disposable": False, "reason": "allowed", "mx": mx_ok, "suspicious": False, "suspicious_reasons": []}

    # 2) blocklist quick check
    if domain in BLOCKSET:
        return {"valid": False, "disposable": True, "reason": "blocklist", "mx": False, "suspicious": False, "suspicious_reasons": []}

    # 3) heuristics
    heur = heuristic_suspicious(email)
    suspicious = heur["suspicious"]
    reasons = heur["reasons"]

    # 4) MX check — if no mx and not allowlisted, treat as disposable (but flexible)
    mx_ok = check_mx(domain)
    if not mx_ok:
        # domains with no MX are usually disposable or mistyped — mark invalid
        return {"valid": False, "disposable": True, "reason": "no_mx", "mx": False, "suspicious": suspicious, "suspicious_reasons": reasons}

    # 5) default allow
    return {"valid": True, "disposable": False, "reason": "valid", "mx": True, "suspicious": suspicious, "suspicious_reasons": reasons}

# -----------------------
# FastAPI Models
# -----------------------
class VerifyRequest(BaseModel):
    email: EmailStr
    api_key: Optional[str] = None

# -----------------------
# Endpoints
# -----------------------
@app.get("/status/")
def status():
    return {"service": APP_NAME, "time": int(time.time()), "block_count": len(BLOCKSET), "allow_count": len(ALLOWSET)}

@app.post("/verify", response_model=dict)
async def verify_post(payload: VerifyRequest):
    # API key first (recommended): check optional both header or payload
    api_key = payload.api_key
    # if not provided in body, try header (clients)
    # for FastAPI, we can get headers from request state but here we rely on payload primarily
    if not api_key:
        # you can choose to allow anonymous requests for testing - if so, comment out the next line
        raise HTTPException(status_code=401, detail="api_key required in POST body")

    valid, reason, client_name = is_key_valid(api_key)
    if not valid:
        raise HTTPException(status_code=403, detail=f"API key {reason}")

    # daily rate limiting
    # find client's configured limit
    keys_map = load_keys()
    client_info = None
    # first search keys_map for client's entry
    for name, info in keys_map.items():
        # info may be dict with 'key' or top-level keyed by key
        if isinstance(info, dict) and info.get("key") == api_key:
            client_info = info
            client_name = name
            break
        if name == api_key:
            client_info = info
            client_name = info.get("client", client_name)
            break

    limit = client_info.get("limit", DEFAULT_DAILY_LIMIT) if client_info else DEFAULT_DAILY_LIMIT
    usage = get_daily_usage(client_name)
    if usage >= limit:
        raise HTTPException(status_code=429, detail="Daily limit reached")

    # do verify
    res = verify_email_address(payload.email)
    # increment usage
    increment_usage(client_name)
    return {"email": payload.email, **res}

@app.get("/verify")
def verify_get(email: str = "", api_key: Optional[str] = None):
    # convenience endpoint used by Cloudflare worker / browser GET calls
    if not email:
        raise HTTPException(status_code=400, detail="Please provide ?email=someone@domain.tld")
    if not api_key:
        raise HTTPException(status_code=401, detail="api_key required (use demo_key_123 for testing)")
    valid, reason, client_name = is_key_valid(api_key)
    if not valid:
        raise HTTPException(status_code=403, detail=f"API key {reason}")

    # rate limit
    keys_map = load_keys()
    client_info = None
    for name, info in keys_map.items():
        if isinstance(info, dict) and info.get("key") == api_key:
            client_info = info
            client_name = name
            break
        if name == api_key:
            client_info = info
            client_name = info.get("client", client_name)
            break
    limit = client_info.get("limit", DEFAULT_DAILY_LIMIT) if client_info else DEFAULT_DAILY_LIMIT
    usage = get_daily_usage(client_name)
    if usage >= limit:
        raise HTTPException(status_code=429, detail="Daily limit reached")
    res = verify_email_address(email)
    increment_usage(client_name)
    out = {"email": email, **res}
    return out

# Admin endpoint to create a key (protected by MASTER_KEY env var)
class CreateKeyRequest(BaseModel):
    client_name: str
    days: int = 365
    plan: str = "pro"
    limit: int = DEFAULT_DAILY_LIMIT

@app.post("/create-key")
def create_key(payload: CreateKeyRequest, master_key: Optional[str] = None):
    # read master key from header if not provided
    from fastapi import Header
    # this function will be called by FastAPI; get header
    # but easier: check global MASTER_KEY env
    # require user to provide header X-Master-Key or pass as param
    # simple check:
    # (FastAPI dependency injection for header omitted for brevity)
    if MASTER_KEY and MASTER_KEY != "master_demo_key":
        # require header present
        raise HTTPException(status_code=403, detail="Master key enabled; use admin flow")
    # If MASTER_KEY left default, allow creation (development)
    keys_map = load_keys()
    # generate UUID v4
    import uuid
    key = str(uuid.uuid4())
    entry = {"key": key, "expiry": int(time.time()) + payload.days * 86400, "plan": payload.plan, "limit": payload.limit}
    # store under client name
    keys_map[payload.client_name] = entry
    write_json(KEYS_FILE, keys_map)
    return {"created": True, "key": key, "entry": entry}

@app.post("/update-lists")
def update_lists_endpoint(master_key: Optional[str] = None):
    # manual refresh of lists (reads from disk updated by updater.py / auto_updater)
    info = reload_lists()
    return {"updated": True, **info}

# -----------------------
# Startup / shutdown hooks
# -----------------------
@app.on_event("startup")
def startup_event():
    # ensure files exist
    if not os.path.exists(KEYS_FILE):
        write_json(KEYS_FILE, {})
    if not os.path.exists(CLIENT_FILE):
        write_json(CLIENT_FILE, {})
    # load lists
    reload_lists()
    # load mx cache (already loaded)
    # spawn background thread occasionally to persist MX cache every 60s
    def mx_persister():
        while True:
            time.sleep(60)
            try:
                save_mx_cache()
            except:
                pass
    t = threading.Thread(target=mx_persister, daemon=True)
    t.start()

@app.on_event("shutdown")
def shutdown_event():
    try:
        save_mx_cache()
    except:
        pass

# -----------------------
# Small CLI test if run as script
# -----------------------
if __name__ == "__main__":
    print("Truemailer main.py - quick local test")
    print("Blocklist:", len(BLOCKSET), "Allowlist:", len(ALLOWSET))
    print("MX cache entries:", len(MX_CACHE))
    while True:
        try:
            em = input("Email to test (or 'exit'): ").strip()
            if em in ("exit", "quit"):
                break
            print(json.dumps(verify_email_address(em), indent=2))
        except KeyboardInterrupt:
            break
